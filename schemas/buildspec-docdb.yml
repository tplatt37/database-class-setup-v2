version: 0.2

phases:
  pre_build:
    commands:
      
      #
      # This is the buildspec.yml (CodeBuild "Build Instructions") that are used to load schema/database/data
      # into each of the databases.  It's all done in one long build project for simplicity sake.
      #
      
      # Dynamically determine which account we are. I do not want to embed any account id into these files.
      - ACCOUNTID=$(aws sts get-caller-identity --query "Account" --output text)
      - echo "AccountID=$ACCOUNTID"
      
      - REGION=${AWS_DEFAULT_REGION:-$(aws configure get default.region)}
      - echo "Region=$REGION"

      # Which shell are we using?
      - echo "Using shell..."
      - ls -lha $(which sh) 
      
      # Always good to know what version of AWS CLI you are dealing with...
      - aws --version

      - PREFIX="database"
      
      # First, we have to pull a whole lot of information from the various Stack Exports.

      # DocumentDB
      - DOCDB_HOST=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-DocDBEndpoint'].Value" --output text)
      - echo "DOCDB_HOST=$DOCDB_HOST"

      - DOCDB_PORT=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-DocDBPort'].Value" --output text)
      - echo "DOCDB_PORT=$DOCDB_PORT"

      # Get the dbadmin password from SecretsManager
      # But first, need to grab the ARN of it from a stack export
      - SECRET_ARN=$(aws cloudformation list-exports --query "Exports[?Name=='$PREFIX-DBAdminSecretArn'].Value" --output text)
      - echo "SECRET_ARN=$SECRET_ARN" 
      
      # Use a combination of client side query and jq to parse out the username and password from the secret.
      - USER=$(aws secretsmanager get-secret-value --secret-id $SECRET_ARN --query "SecretString" --output text | sed 's/\\//g' | jq -r '.username')
      - PASSWORD=$(aws secretsmanager get-secret-value --secret-id $SECRET_ARN --query "SecretString" --output text | sed 's/\\//g' | jq -r '.password')
      # For debugging purposes show the LENGTH of the USER/PASSWORD 
      # If it's ZERO that means an issue retrieving it from SecretsManager.
      - echo "Lengths:"
      - echo ${#USER}
      - echo ${#PASSWORD}
  
      # Install other things that we need.
  
      # Get the PEM and crt files needed to connect securely to the databases
      - wget https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem
      - wget https://s3.amazonaws.com/redshift-downloads/amazon-trust-ca-bundle.crt
      - wget https://truststore.pki.rds.amazonaws.com/global/global-bundle.pem
      - ls -lha *.pem
      
      # https://docs.mongodb.com/manual/tutorial/install-mongodb-on-amazon/
      # First, mongo
      - cp mongodb-org-5.0.repo /etc/yum.repos.d/
      
      # mongocli
      - yum install -y mongodb-org
      - mongo --version
      - mongoimport --version
      
  build:
    commands:
      - echo Started on `date`. >> report.txt
      
      #
      # Lets load some database schemas , and data
      # This pipeline is idempotent, but be aware it wilL DROP your existing database(s)!
      # This is desired, because we probably want to start each class or demo in a consistent, known state.
      # Please also note this pipeline runs for ALL THE DATABASES!
      # It is not meant to be a production, real-world example - the purpose is to get us set up to teach a class.
      #
      
      #
      # Docdb via Mongoimport
      # This is the "Cases" sample file from:
      # https://github.com/aws-samples/amazon-documentdb-samples
      #
      
      # First, download this file live. it's too big to put in the Repo (CFN Limits us to 6MB zip max)
      - wget -q https://raw.githubusercontent.com/aws-samples/amazon-documentdb-samples/master/datasets/cases.json 1> /dev/null
      - mongoimport --db cases --collection casecollection --host $DOCDB_HOST --port $DOCDB_PORT  --sslCAFile global-bundle.pem  --ssl  --authenticationDatabase admin --username $USER --password $PASSWORD --drop --file cases.json 1>/dev/null
    
  post_build:
    commands:
      - echo Completed on `date` >> report.txt
      - cat report.txt
artifacts:
    files: 
      - report.txt